"""
Pascal VOC â†’ YOLO í˜•ì‹ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
Safety-Helmet-Wearing-Dataset ì „ìš©
"""

import os
import xml.etree.ElementTree as ET
import shutil
from pathlib import Path

# í´ë˜ìŠ¤ ë§¤í•‘
CLASS_MAPPING = {
    'hat': 0,      # helmet (í—¬ë©§ ì°©ìš©)
    'person': 1    # no_helmet (í—¬ë©§ ë¯¸ì°©ìš©)
}

def convert_voc_box_to_yolo(size, box):
    """
    VOC bounding box â†’ YOLO í˜•ì‹ ë³€í™˜

    Args:
        size: (width, height) ì´ë¯¸ì§€ í¬ê¸°
        box: (xmin, ymin, xmax, ymax) VOC bbox

    Returns:
        (x_center, y_center, width, height) normalized
    """
    dw = 1.0 / size[0]
    dh = 1.0 / size[1]

    x_center = (box[0] + box[2]) / 2.0
    y_center = (box[1] + box[3]) / 2.0
    width = box[2] - box[0]
    height = box[3] - box[1]

    # Normalize
    x_center *= dw
    y_center *= dh
    width *= dw
    height *= dh

    return (x_center, y_center, width, height)

def convert_annotation(xml_path, output_txt_path):
    """
    í•˜ë‚˜ì˜ XML íŒŒì¼ì„ YOLO txt íŒŒì¼ë¡œ ë³€í™˜

    Args:
        xml_path: Pascal VOC XML íŒŒì¼ ê²½ë¡œ
        output_txt_path: ì¶œë ¥ YOLO txt íŒŒì¼ ê²½ë¡œ
    """
    tree = ET.parse(xml_path)
    root = tree.getroot()

    # ì´ë¯¸ì§€ í¬ê¸°
    size = root.find('size')
    w = int(size.find('width').text)
    h = int(size.find('height').text)

    # YOLO ë¼ë²¨ ë¦¬ìŠ¤íŠ¸
    yolo_labels = []

    # ëª¨ë“  ê°ì²´ ì²˜ë¦¬
    for obj in root.iter('object'):
        cls_name = obj.find('name').text

        # í´ë˜ìŠ¤ ë§¤í•‘ í™•ì¸
        if cls_name not in CLASS_MAPPING:
            print(f"âš ï¸ Unknown class: {cls_name} in {xml_path}")
            continue

        cls_id = CLASS_MAPPING[cls_name]

        # Bounding box
        xmlbox = obj.find('bndbox')
        xmin = float(xmlbox.find('xmin').text)
        ymin = float(xmlbox.find('ymin').text)
        xmax = float(xmlbox.find('xmax').text)
        ymax = float(xmlbox.find('ymax').text)

        # VOC â†’ YOLO ë³€í™˜
        yolo_box = convert_voc_box_to_yolo((w, h), (xmin, ymin, xmax, ymax))

        # YOLO ë¼ë²¨ í˜•ì‹: class x_center y_center width height
        yolo_label = f"{cls_id} {yolo_box[0]:.6f} {yolo_box[1]:.6f} {yolo_box[2]:.6f} {yolo_box[3]:.6f}\n"
        yolo_labels.append(yolo_label)

    # íŒŒì¼ ì €ì¥
    if yolo_labels:
        with open(output_txt_path, 'w') as f:
            f.writelines(yolo_labels)
        return True
    else:
        return False

def convert_dataset(voc_dir, output_dir):
    """
    ì „ì²´ ë°ì´í„°ì…‹ ë³€í™˜

    Args:
        voc_dir: Pascal VOC ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ (SHWD/)
        output_dir: YOLO í˜•ì‹ ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    voc_dir = Path(voc_dir)
    output_dir = Path(output_dir)

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    for split in ['train', 'val', 'test']:
        (output_dir / 'images' / split).mkdir(parents=True, exist_ok=True)
        (output_dir / 'labels' / split).mkdir(parents=True, exist_ok=True)

    # ê° split ì²˜ë¦¬
    splits = ['train', 'val', 'test']
    stats = {'train': 0, 'val': 0, 'test': 0}

    for split in splits:
        print(f"\nğŸ“‚ Processing {split} set...")

        # ImageSets/Main/{split}.txt ì½ê¸°
        split_file = voc_dir / 'ImageSets' / 'Main' / f'{split}.txt'

        if not split_file.exists():
            print(f"âš ï¸ {split_file} not found, skipping {split}")
            continue

        with open(split_file, 'r') as f:
            image_ids = [line.strip() for line in f.readlines()]

        print(f"  Found {len(image_ids)} images")

        # ê° ì´ë¯¸ì§€ ì²˜ë¦¬
        for img_id in image_ids:
            # XML ê²½ë¡œ
            xml_path = voc_dir / 'Annotations' / f'{img_id}.xml'

            if not xml_path.exists():
                print(f"âš ï¸ XML not found: {xml_path}")
                continue

            # ì´ë¯¸ì§€ ê²½ë¡œ
            img_path = voc_dir / 'JPEGImages' / f'{img_id}.jpg'

            if not img_path.exists():
                print(f"âš ï¸ Image not found: {img_path}")
                continue

            # YOLO txt ê²½ë¡œ
            txt_path = output_dir / 'labels' / split / f'{img_id}.txt'

            # ë³€í™˜
            success = convert_annotation(xml_path, txt_path)

            if success:
                # ì´ë¯¸ì§€ ë³µì‚¬
                dst_img_path = output_dir / 'images' / split / f'{img_id}.jpg'
                shutil.copy2(img_path, dst_img_path)
                stats[split] += 1

        print(f"  âœ… Converted {stats[split]} images")

    # data.yaml ìƒì„±
    create_data_yaml(output_dir, stats)

    print(f"\n{'='*60}")
    print(f"âœ… ë³€í™˜ ì™„ë£Œ!")
    print(f"{'='*60}")
    print(f"Train: {stats['train']} images")
    print(f"Val: {stats['val']} images")
    print(f"Test: {stats['test']} images")
    print(f"Total: {sum(stats.values())} images")
    print(f"\nì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")

def create_data_yaml(output_dir, stats):
    """
    data.yaml íŒŒì¼ ìƒì„±

    Args:
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        stats: ê° splitë³„ ì´ë¯¸ì§€ ê°œìˆ˜
    """
    yaml_content = f"""# Safety-Helmet-Wearing-Dataset (YOLO format)
# Converted from Pascal VOC format

# Dataset root
path: {output_dir.absolute()}

# Splits
train: images/train  # {stats['train']} images
val: images/val      # {stats['val']} images
test: images/test    # {stats['test']} images

# Classes
names:
  0: helmet      # í—¬ë©§ ì°©ìš© (ì›ë³¸: hat)
  1: no_helmet   # í—¬ë©§ ë¯¸ì°©ìš© (ì›ë³¸: person)

# Original dataset info
# Source: https://github.com/njvisionpower/Safety-Helmet-Wearing-Dataset
# License: MIT
# Total images: {sum(stats.values())}
# Detection type: Person-level
"""

    yaml_path = output_dir / 'data.yaml'
    with open(yaml_path, 'w', encoding='utf-8') as f:
        f.write(yaml_content)

    print(f"\nğŸ“ data.yaml ìƒì„±: {yaml_path}")

if __name__ == "__main__":
    # ê²½ë¡œ ì„¤ì •
    BASE_DIR = Path.home() / "Developments" / "mirae-city" / "orin-yolo"
    VOC_DIR = BASE_DIR / "datasets" / "SHWD" / "VOC2028"
    OUTPUT_DIR = BASE_DIR / "datasets" / "helmet-detection"

    print("="*60)
    print("Pascal VOC â†’ YOLO ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸")
    print("Safety-Helmet-Wearing-Dataset")
    print("="*60)
    print(f"\nì…ë ¥ ë””ë ‰í† ë¦¬: {VOC_DIR}")
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {OUTPUT_DIR}")

    # VOC ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
    if not VOC_DIR.exists():
        print(f"\nâŒ ì˜¤ë¥˜: VOC ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {VOC_DIR}")
        print(f"\në‹¤ìš´ë¡œë“œ ì•ˆë‚´:")
        print(f"1. https://github.com/njvisionpower/Safety-Helmet-Wearing-Dataset")
        print(f"2. Google Drive/Baidu Driveì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ")
        print(f"3. {VOC_DIR} ì— ì••ì¶• í•´ì œ")
        exit(1)

    # ë³€í™˜ ì‹œì‘
    user_input = input("\në³€í™˜ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")

    if user_input.lower() == 'y':
        convert_dataset(VOC_DIR, OUTPUT_DIR)

        print(f"\në‹¤ìŒ ë‹¨ê³„:")
        print(f"1. data.yaml ê²½ë¡œ í™•ì¸: {OUTPUT_DIR / 'data.yaml'}")
        print(f"2. í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ data.yaml ì‚¬ìš©")
        print(f"3. í•™ìŠµ ì‹œì‘!")
    else:
        print("ë³€í™˜ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
